{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# chat_model은 대화에 더욱 최적화 = LLM이 질문을 받기만 하는게 아니라 LLM과 대화를 할 수 있다.\n",
    "chat = ChatOpenAI(temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하나의 텍스트(String)를 predict 하는게 아니라 --> chat.predict(...)\n",
    "# message들을 predict 해보자\n",
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage # message Constructor\n",
    "\n",
    "# SystemMessage --> AI(LLM)에 기본 설정, 기본 값, 기본 context를 제공하기 위한 메시지\n",
    "# AIMessage     --> AI에 의해 보내지는 메시지\n",
    "# HumanMessage  --> 사람이 보내는 메시지\n",
    "\n",
    "messages = [\n",
    "    # LLM 기본 설정\n",
    "    SystemMessage(content=\"You are a geography expert. And you only reply in Korean.\"),\n",
    "    # 일종의 가상 대화, '대화의 맥락에서 AI가 이렇게 말을 한 것이다.'라고 생각하면 된다.\n",
    "    # 참고로 '메모리(memory)'에 이러한 정보가 저장된다.\n",
    "    AIMessage(content=\"안녕하세요, 내 이름은 테리우스입니다.\"),\n",
    "    # 위의 AIMessage(가상 대화) 다음에 사용자로서 사람이 던지는 질문\n",
    "    HumanMessage(content=\"\"\"What is the distance between Mexico and Thailand. Also, what is your name?\"\"\")\n",
    "]\n",
    "\n",
    "chat.predict_messages(messages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
